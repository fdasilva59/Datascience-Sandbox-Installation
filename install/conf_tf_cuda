#!/usr/bin/expect -f
#
# This Expect script was generated by autoexpect on Thu Sep  8 21:41:26 2016
# Expect and autoexpect were both written by Don Libes, NIST.
#
# Note that autoexpect does not guarantee a working script.  It
# necessarily has to guess about certain things.  Two reasons a script
# might fail are:
#
# 1) timing - A surprising number of programs (rn, ksh, zsh, telnet,
# etc.) and devices discard or ignore keystrokes that arrive "too
# quickly" after prompts.  If you find your new script hanging up at
# one spot, try adding a short sleep just before the previous send.
# Setting "force_conservative" to 1 (see below) makes Expect do this
# automatically - pausing briefly before sending each character.  This
# pacifies every program I know of.  The -c flag makes the script do
# this in the first place.  The -C flag allows you to define a
# character to toggle this mode off and on.

set force_conservative 0  ;# set to 1 to force conservative mode even if
			  ;# script wasn't run conservatively originally
if {$force_conservative} {
	set send_slow {1 .1}
	proc send {ignore arg} {
		sleep .1
		exp_send -s -- $arg
	}
}

#
# 2) differing output - Some programs produce different output each time
# they run.  The "date" command is an obvious example.  Another is
# ftp, if it produces throughput statistics at the end of a file
# transfer.  If this causes a problem, delete these patterns or replace
# them with wildcards.  An alternative is to use the -p flag (for
# "prompt") which makes Expect only look for the last line of output
# (i.e., the prompt).  The -P flag allows you to define a character to
# toggle this mode off and on.
#
# Read the man page for more info.
#
# -Don

set timeout -1
spawn ./configure
match_max 100000
expect -exact "Please specify the location of python. \[Default is /usr/bin/python\]: "
send -- "\r"
expect -exact "\r
Do you wish to build TensorFlow with Google Cloud Platform support? \[y/N\] "
send -- "N\r"
expect -exact "N\r
No Google Cloud Platform support will be enabled for TensorFlow\r
Do you wish to build TensorFlow with Hadoop File System support? \[y/N\] "
send -- "N\r"
expect -exact "N\r
No Hadoop File System support will be enabled for TensorFlow\r
Found possible Python library paths:\r
  /usr/lib/python2.7/dist-packages\r
  /usr/local/lib/python2.7/dist-packages\r
Please input the desired Python library path to use.  Default is \[/usr/lib/python2.7/dist-packages\]\r
"
send -- "\r"
expect -exact "\r
/usr/lib/python2.7/dist-packages\r
Do you wish to build TensorFlow with GPU support? \[y/N\] "
send -- "y\r"
expect -exact "y\r
GPU support will be enabled for TensorFlow\r
Please specify which gcc should be used by nvcc as the host compiler. \[Default is /usr/bin/gcc\]: "
send -- "\r"
expect -exact "\r
Please specify the Cuda SDK version you want to use, e.g. 7.0. \[Leave empty to use system default\]: "
send -- "\r"
expect -exact "\r
Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. \[Default is /usr/local/cuda\]: "
send -- "\r"
expect -exact "\r
Please specify the Cudnn version you want to use. \[Leave empty to use system default\]: "
send -- "\r"
expect -exact "\r
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. \[Default is /usr/local/cuda\]: "
send -- "\r"
expect -exact "\r
libcudnn.so resolves to libcudnn.5\r
Please specify a list of comma-separated Cuda compute capabilities you want to build with.\r
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r
Please note that each additional compute capability significantly increases your build time and binary size.\r
\[Default is: \"3.5,5.2\"\]: "
send -- "6.1\r"
expect eof
xpect -exact "\r
Please specify the Cudnn version you want to use. \[Leave empty to use system default\]: "
send -- "\r"
expect -exact "\r
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. \[Default is /usr/local/cuda\]: "
send -- "\r"
expect -exact "\r
libcudnn.so resolves to libcudnn.5\r
Please specify a list of comma-separated Cuda compute capabilities you want to build with.\r
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r
Please note that each additional compute capability significantly increases your build time and binary size.\r
\[Default is: \"3.5,5.2\"\]: "
send -- "6.1\r"
